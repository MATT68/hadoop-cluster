
 Lanzando el cluster de hadoop en docker:
 
 1.- Tenemos creada la image base, hadoop-base.
 
 2.- En la nueva imagen debemos :
    - Configurar ssh
	- Copiar ficheros de config *.xml
    - Subir fichero indicando número de slaves en el cluster 	
	- etc.
    Esa nueva imagen la usaremos para crear un container por cada máquina/servicio del cluster.
     Por tanto al arrancar cada una debemos tener en cuenta las diferencias entre el master y 
     los slaves.
     En el bootstrap.sh del master se debe formatear el hdfs de inicio. En el resto no.
 
 3.- Vamos a crear una imagen para el hadoop-master y otra diferente para los hadoop-slaves.
	Por tanto, necesitamos dos contextos docker y crear sendas imágenes.
	
    docker build - t matt68/hadooop-master:3.2  . 
    docker build - t matt68/hadooop-slave:3.2  . 
	
 4.- Volumen. Almacenar datos. Windows tiene una configuración especial para ello.
    
	Notice: all the data in containers are not persisted, so they will lose when restarts. 
	
 5.- Debemos definir/arrancar cada servicio del swarm :
    browse start_hadoop.sh for full script

  xx -- Start master node
   docker service create \
	--name hadoop-master \
	--network swarm-net \
	--hostname hadoop-master \
	--constraint node.role==manager \
	--replicas 1 \
	--endpoint-mode dnsrr \
	matt68/hadooop-node:3.2
	
   xx -- Start 3 slaves
   docker service create \
	--name hadoop-slave1 \
	--network swarm-net \
	--hostname hadoop-slave1 \
	--replicas 1 \
	--endpoint-mode dnsrr \
	matt68/hadooop-node:3.2

  docker service create \
	--name hadoop-slave2 \
	--network swarm-net \
	--hostname hadoop-slave2 \
	--replicas 1 \
	--endpoint-mode dnsrr \
	matt68/hadooop-node:3.2

   docker service create \
	--name hadoop-slave3 \
	--network swarm-net \
	--hostname hadoop-slave3 \
	--replicas 1 \
	--endpoint-mode dnsrr \
	matt68/hadooop-node:3.2
	
	

	